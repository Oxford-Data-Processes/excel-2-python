{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing section: series_extraction\n",
      "{'ExcelCleaner.clean_excel': ['TableFinder.find_tables',\n",
      "                              'SeriesExtractor.extract_series'],\n",
      " 'ExcelCompatibilityChecker.check_file': ['SeriesExtractor.extract_series'],\n",
      " 'ExcelLoader.load_file': ['ExcelCompatibilityChecker.check_file',\n",
      "                           'ExcelValidator.validate_excel',\n",
      "                           'ExcelCleaner.clean_excel'],\n",
      " 'ExcelValidator.validate_excel': ['ExcelCleaner.clean_excel'],\n",
      " 'SeriesExtractor.extract_series': ['SeriesIterator.iterate_series'],\n",
      " 'TableFinder.find_tables': ['SeriesExtractor.extract_series']}\n",
      "\n",
      "\n",
      "Processing section: ast_building\n",
      "{'FormulaParser.parse_formula': ['SeriesImplementer.implement_series',\n",
      "                                 'SeriesImplementer.implement_series']}\n",
      "\n",
      "\n",
      "Processing section: ast_transformation\n",
      "{'FormulaGenerator.get_ast_generator': ['FunctionReplacer.replace_functions'],\n",
      " 'FunctionReplacer.replace_functions': ['ASTGeneratorCollector.get_collection']}\n",
      "\n",
      "\n",
      "Processing section: pipeline_building\n",
      "{'DAGSorter.sort_dag': ['PipelineBuilder.build_pipeline'],\n",
      " 'SeriesDependenciesBuilder.build_dependencies': ['DAGSorter.sort_dag']}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the path to your YAML file\n",
    "yaml_file_path = 'pipeline_flow.yml'\n",
    "\n",
    "# Function to extract DAG from a section of the pipeline\n",
    "def extract_dag_for_section(section_data):\n",
    "    dag = defaultdict(list)  # Adjacency list representation of the DAG\n",
    "    \n",
    "    # Maps outputs to step names to identify dependencies\n",
    "    output_to_step = {}\n",
    "    \n",
    "    for step in section_data:\n",
    "        step_name = step.get('step')\n",
    "        inputs = step.get('inputs', [])\n",
    "        outputs = step.get('outputs', [])\n",
    "        \n",
    "        # Assume dependencies based on matching inputs to previously mapped outputs\n",
    "        for input_item in inputs:\n",
    "            for input_key, input_value in input_item.items():\n",
    "                if input_key in output_to_step:\n",
    "                    # Add dependency from output provider to current step\n",
    "                    dag[output_to_step[input_key]].append(step_name)\n",
    "        \n",
    "        # Map current step's outputs for future dependency checks\n",
    "        for output_item in outputs:\n",
    "            for output_key, output_value in output_item.items():\n",
    "                output_to_step[output_key] = step_name\n",
    "                \n",
    "    return dag\n",
    "\n",
    "# Open the YAML file and load its contents\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Assuming the config has top-level keys corresponding to sections\n",
    "for section_name, section_data in config.items():\n",
    "    print(f\"Processing section: {section_name}\")\n",
    "    dag = extract_dag_for_section(section_data)\n",
    "    pprint(dict(dag))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'series_extraction': [{'step': 'ExcelLoader.load_file',\n",
       "   'inputs': [{'excel_raw_file_path': {'type': 'str',\n",
       "      'description': 'Path to raw Excel'}},\n",
       "    {'excel_reduced_file_path': {'type': 'str',\n",
       "      'description': 'Path to Excel with only two rows per table'}}],\n",
       "   'outputs': [{'excel_raw': {'type': 'ExcelFile',\n",
       "      'description': 'Loaded raw Excel'}},\n",
       "    {'excel_reduced': {'type': 'ExcelFile',\n",
       "      'description': 'Loaded raw Excel file'}}]},\n",
       "  {'step': 'ExcelCompatibilityChecker.check_file',\n",
       "   'inputs': [{'excel_raw': {'type': 'ExcelFile',\n",
       "      'description': 'Loaded raw Excel'}},\n",
       "    {'extracted_tables': {'type': 'dict[Worksheet, list[Table]]',\n",
       "      'description': 'Located tables inside an Excel with table metadata'}}],\n",
       "   'outputs': [{'is_compatible': {'type': 'bool',\n",
       "      'description': 'True if the files are compatible'}}],\n",
       "   'decision_point': 'is_compatible',\n",
       "   'actions': [{'result': True, 'next_step': 'SeriesExtractor.extract_series'},\n",
       "    {'result': False, 'next_step': 'end_process'}]},\n",
       "  {'step': 'ExcelValidator.validate_excel',\n",
       "   'inputs': [{'excel_reduced': {'type': 'ExcelFile',\n",
       "      'description': 'Loaded raw Excel file'}}],\n",
       "   'outputs': [{'is_valid': {'type': 'bool',\n",
       "      'description': 'True if the Excel is valid'}}],\n",
       "   'decision_point': 'is_valid',\n",
       "   'actions': [{'result': True, 'next_step': 'ExcelCleaner.clean_excel'},\n",
       "    {'result': False, 'next_step': 'end_process'}]},\n",
       "  {'step': 'ExcelCleaner.clean_excel',\n",
       "   'inputs': [{'excel_reduced': {'type': 'ExcelFile',\n",
       "      'description': 'Loaded raw Excel file'}},\n",
       "    {'is_valid': {'type': 'bool',\n",
       "      'description': 'True if the Excel is valid'}}],\n",
       "   'outputs': [{'excel_reduced_clean': {'type': 'ExcelFile',\n",
       "      'description': 'Excel with only two rows per table with formulas cleaned'}}],\n",
       "   'next_step': 'TableFinder.find_tables'},\n",
       "  {'step': 'TableFinder.find_tables',\n",
       "   'inputs': [{'excel_reduced_clean': {'type': 'ExcelFile',\n",
       "      'description': 'Excel with only two rows per table with formulas cleaned'}}],\n",
       "   'outputs': [{'extracted_tables': {'type': 'dict[Worksheet, list[Table]]',\n",
       "      'description': 'Located tables inside an Excel with table metadata'}}],\n",
       "   'next_step': 'SeriesExtractor.extract_series'},\n",
       "  {'step': 'SeriesExtractor.extract_series',\n",
       "   'inputs': [{'excel_reduced_clean': {'type': 'ExcelFile',\n",
       "      'description': 'Excel with only two rows per table with formulas cleaned'}},\n",
       "    {'extracted_tables': {'type': 'dict[Worksheet, list[Table]]',\n",
       "      'description': 'Located tables inside an Excel with table metadata'}},\n",
       "    {'is_compatible': {'type': 'bool',\n",
       "      'description': 'True if the files are compatible'}}],\n",
       "   'outputs': [{'series_data': {'type': 'dict[UUID, list[Series]]',\n",
       "      'description': 'Collection of series'}}]},\n",
       "  {'step': 'SeriesIterator.iterate_series',\n",
       "   'inputs': [{'series_data': {'type': 'dict[UUID, list[Series]]',\n",
       "      'description': 'Collection of series'}}],\n",
       "   'outputs': [{'series_data_iterator': {'type': 'Iterator[Series]',\n",
       "      'description': 'Iterator over the series'}}]}],\n",
       " 'ast_building': [{'step': 'FormulaParser.parse_formula',\n",
       "   'inputs': [{'formula_1': {'type': 'str',\n",
       "      'description': 'First Excel formula inside a series'}},\n",
       "    {'formula_2': {'type': 'str',\n",
       "      'description': 'Second Excel formula inside a series'}}],\n",
       "   'outputs': [{'formula_1_ast': {'type': 'xlcalculator.ast_nodes.ASTNode',\n",
       "      'description': 'Represents the starting node of the AST for formula_1, which can be traversed'}},\n",
       "    {'formula_2_ast': {'type': 'xlcalculator.ast_nodes.ASTNode',\n",
       "      'description': 'Represents the starting node of the AST for formula_2, which can be traversed'}}]},\n",
       "  {'step': 'SeriesImplementer.implement_series',\n",
       "   'inputs': [{'formula_1_ast': {'type': 'xlcalculator.ast_nodes.ASTNode',\n",
       "      'description': 'Represents the starting node of the AST for formula_1, which can be traversed'}},\n",
       "    {'formula_2_ast': {'type': 'xlcalculator.ast_nodes.ASTNode',\n",
       "      'description': 'Represents the starting node of the AST for formula_2, which can be traversed'}}],\n",
       "   'outputs': [{'formula_1_ast_series': {'type': 'xlcalculator.ast_nodes.ASTNode',\n",
       "      'description': 'Represents the starting node of the AST for formula_1, but with SeriesRange objects instead of RangeNode objects'}},\n",
       "    {'formula_2_ast_series': {'type': 'xlcalculator.ast_nodes.ASTNode',\n",
       "      'description': 'Represents the starting node of the AST for formula_2, but with SeriesRange objects instead of RangeNode objects'}}]}],\n",
       " 'ast_transformation': [{'step': 'FormulaGenerator.get_ast_generator',\n",
       "   'inputs': [{'formula_1_ast_series': {'type': 'xlcalculator.ast_nodes.ASTNode',\n",
       "      'description': 'Represents the starting node of the AST for formula_1, but with SeriesRange objects instead of RangeNode objects'}},\n",
       "    {'formula_2_ast_series': {'type': 'xlcalculator.ast_nodes.ASTNode',\n",
       "      'description': 'Represents the starting node of the AST for formula_2, but with SeriesRange objects instead of RangeNode objects'}}],\n",
       "   'outputs': [{'ast_generator': {'type': 'ASTGenerator',\n",
       "      'description': 'An object with a get_ast() method that returns the ast of the nth index'}}]},\n",
       "  {'step': 'FunctionReplacer.replace_functions',\n",
       "   'inputs': [{'ast_generator': {'type': 'ASTGenerator',\n",
       "      'description': 'An object with a get_ast() method that returns the ast of the nth index'}}],\n",
       "   'composition': [{'util_class': 'FunctionTranslator'}],\n",
       "   'outputs': [{'ast_generator_python': {'type': 'ASTGeneratorPython',\n",
       "      'description': 'An object with a get_ast_python() method but where the ast output has PythonFunction objects instead of FunctionNode objects.'}}]},\n",
       "  {'step': 'ASTGeneratorCollector.get_collection',\n",
       "   'inputs': [{'ast_generator_python': {'type': 'ASTGeneratorPython',\n",
       "      'description': 'An object with a get_ast_python() method but where the ast output has PythonFunction objects instead of FunctionNode objects.'}}],\n",
       "   'outputs': [{'ast_generator_collection': {'type': 'dict[UUID, ASTGeneratorPython]',\n",
       "      'description': 'Dictionary where keys are series_id values and the values are ASTGeneratorPython objects'}}]}],\n",
       " 'pipeline_building': [{'step': 'SeriesDependenciesBuilder.build_dependencies',\n",
       "   'inputs': [{'formula_1_ast_series_list': {'type': 'list[xlcalculator.ast_nodes.ASTNode]',\n",
       "      'description': 'List of AST nodes for formula_1 with SeriesRange objects instead of RangeNode objects'}}],\n",
       "   'outputs': [{'series_dependencies': {'type': 'dict[UUID, list[UUID]]',\n",
       "      'description': 'Dictionary where keys are series_ids and the values are the series_ids which are dependencies for each series'}}]},\n",
       "  {'step': 'DAGSorter.sort_dag',\n",
       "   'inputs': [{'series_dependencies': {'type': 'dict[UUID, list[UUID]]',\n",
       "      'description': 'Dictionary where keys are series_ids and the values are the series_ids which are dependencies for each series'}}],\n",
       "   'outputs': [{'sorted_dag': {'type': 'list[UUID]',\n",
       "      'description': 'List of series_ids in order of execution'}}]},\n",
       "  {'step': 'PipelineBuilder.build_pipeline',\n",
       "   'inputs': [{'sorted_dag': {'type': 'list[UUID]',\n",
       "      'description': 'List of series_ids in order of execution'}},\n",
       "    {'ast_generator_collection': {'type': 'dict[UUID, ASTGeneratorPython]',\n",
       "      'description': 'Dictionary where keys are series_id values and the values are ASTGeneratorPython objects'}},\n",
       "    {'series_data': {'type': 'dict[UUID, list[Series]]',\n",
       "      'description': 'Collection of series'}}],\n",
       "   'outputs': [{'python_pipeline': {'type': 'str',\n",
       "      'description': 'Python pipeline code'}}]}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Function to create visualization for a given section of the pipeline\n",
    "def create_visualization(section_name, steps):\n",
    "    dot = Digraph(comment=section_name)\n",
    "    dot.attr('node', shape='box')  # Set nodes to be boxes\n",
    "\n",
    "    # Keep track of steps and their outputs for matching inputs to outputs\n",
    "    output_to_step = {}\n",
    "\n",
    "    for step in steps:\n",
    "        step_name = step['step']\n",
    "        step_label = f\"{step_name}\"\n",
    "\n",
    "        # Collect outputs for this step\n",
    "        outputs = [output for output_dict in step.get('outputs', []) for output in output_dict]\n",
    "        if outputs:\n",
    "            step_label += \"\\nOutputs: \" + \", \".join(outputs)\n",
    "            for output in outputs:\n",
    "                output_to_step[output] = step_name\n",
    "\n",
    "        # Create node with step and its outputs as label\n",
    "        dot.node(step_name, label=step_label)\n",
    "\n",
    "    # Add edges based on inputs matching to outputs from other steps\n",
    "    for step in steps:\n",
    "        step_name = step['step']\n",
    "        inputs = [input_key for input_dict in step.get('inputs', []) for input_key in input_dict]\n",
    "        \n",
    "        for input_key in inputs:\n",
    "            # If input matches an output from another step, draw an edge\n",
    "            if input_key in output_to_step:\n",
    "                dot.edge(output_to_step[input_key], step_name, label=input_key)\n",
    "\n",
    "    return dot\n",
    "\n",
    "# For each section in the YAML, create and render a visualization\n",
    "for section_name, steps in config.items():\n",
    "    dot = create_visualization(section_name, steps)\n",
    "    dot.format = 'jpg'\n",
    "    dot.render(f'{section_name}.gv', view=False)  # This will save and optionally open the graph visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
